{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package installation\n",
    "\n",
    "Your first task this time might be the installation of a package. Try running the cell below. If it fails with an `ModuleNotFoundError`, this is because you haven't installed the `pybaseball` package yet. Also it's not a package that's available via any conda channel, so you might have to use the standard-installer pip.\n",
    "\n",
    "Run ```pip install pybaseball``` in your terminal and try importing the packages again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pybaseball\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your own support vector machine\n",
    "\n",
    "Today's practice will deal with support vector machines. Using radial basis functions(RBF) as kernel functions we will analyze everyones' favorite sport: baseball! Due to its popularity you are obviously already familiar with the fact, that the [strike zone](https://de.wikipedia.org/wiki/Strike_Zone), which the pitcher has to hit in order to be awarded a \"strike\" against the batter and will otherwise be punished with a \"ball\", is defined as a rectangle reaching from the player's knees to his chest above the home base. Because this is common knowledge we don't need to mention, that this definition varies from player to player as a result and also the umpire's calls will impact the shape of the real shape of the strike zone. We will build a support vector machine for our favorite players to determine the decision boundary for the judgment, if a pitch will be a strike or a ball.\n",
    "\n",
    "The player, who we'll have a look at, is the 2017 rookie of the year, Aaron Judge, who's 2.01m tall and therefore one of the tallest players in the MLB. Let's see what information is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_id: pd.DataFrame = pybaseball.playerid_lookup(\"Judge\",\"Aaron\")\n",
    "judge_stats: pd.DataFrame = pybaseball.statcast_batter('2010-01-01', '2024-01-01', judge_id[\"key_mlbam\"].iloc[0])\n",
    "print(judge_stats.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration\n",
    "\n",
    "Well this might be a little too much data for now, even for us baseball enthusiasts. If you really want to know what all of these stats mean, I'll refer you to [this site](https://baseballsavant.mlb.com/csv-docs).\n",
    "\n",
    "For now I'll go ahead and pick the relevant columns for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_df: pd.DataFrame = judge_stats[[\"plate_x\", \"plate_z\", \"type\"]].copy() # copy to avoid overwriting original dataframe\n",
    "print(judge_df[100:106])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we go, this is the horizontal(plate_x) and vertical(plate_z) position of the ball when it crosses home plate from the catcher's perspective and whether the pitch resulted in a strike(**S**), ball(**B**) or a successful hit(**X**), but wait... this was too easy. Something feels off.\n",
    "\n",
    "What's that \"mixed types\"-error message in cell number 2 about? Why would I show you the columns 100 to 105 and not simply df.head()? Also if I print columns 100 to 105, why does the index in the output say 30 to 35?\n",
    "\n",
    "Another problem might lure in the \"type\" column. What datatype is it? Why might this be a problem and what would we rather have? \n",
    "\n",
    "Inspect the data yourself and figure out the problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "\n",
    "Firstly, there is a bunch of NaNs in our data. Secondly, SVMs are good with numerical data, but not with categorical data as they want to represent the data as vectors.\n",
    "\n",
    "So we want to map our data to 0s for balls and 1s for strikes. The **map-method** of dataframes comes in super handy for this kind of task. As we are mostly interested in the umpire's decision we will ignore the balls, which went into play. They will turn into NaNs, which we still have to deal with anyway because of the first problem.\n",
    "\n",
    "Create a new column called `\"label\"` in the dataframe, which maps balls and strikes to their respective value and makes NaNs out of successful hits to pass the test cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test cell\n",
    "\n",
    "assert judge_df.get(\"label\") is not None, 'No column called \"label\" exists in judge_df'\n",
    "assert judge_df[\"label\"].dtype in (int, float), \"Data type of the label column should be a numerical data type\"\n",
    "np.testing.assert_equal(judge_df[\"label\"].unique(), np.array([np.nan,  1.,  0.]), \"Unique value of the label column should be [nan,  1.,  0.] in this order\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there is a bunch of NaNs in our data. We should decided what we want to do with these values. If there is some other relevant data in these rows, we might want to replace them with some other value. But in our case we have no reason to keep these rows, so we can just drop them.\n",
    "\n",
    "Clean the data, so that there are no NaNs left.\n",
    "\n",
    "Save the clean df to a variable called `judge_df_cleaned` to pass the test cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_df_cleaned: pd.DataFrame = None # Your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test cell\n",
    "\n",
    "assert judge_df_cleaned is not None, \"Your cleaned dataframe is not defined. Create a new dataframe called judge_df_cleaned by removing all rows with NaN values from judge_df\"\n",
    "\n",
    "assert not judge_df_cleaned.isnull().values.any(), \"There are still NaNs left in your cleaned dataframe\"\n",
    "assert len(judge_df_cleaned) >= 14552 , \"There are less rows than expected in your data frame\"\n",
    "assert len(judge_df_cleaned) <= 14552, \"There are more rows than expected in your data frame\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at how our data actually looks like. I prepared a plot-function for you. Call it with your dataframe(containing the mapped values in a column called `label`) as the only argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(df: pd.DataFrame) -> None:\n",
    "    balls: pd.DataFrame = df[df.label == 0]\n",
    "    strikes: pd.DataFrame = df[df.label == 1]\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ball_scatter = plt.scatter(balls.plate_x, balls.plate_z, c=\"b\", alpha=0.2)\n",
    "    strike_scatter = plt.scatter(strikes.plate_x, strikes.plate_z, c=\"r\", alpha=0.2)\n",
    "    plt.title(\"Strike zone data\")\n",
    "    plt.legend((ball_scatter, strike_scatter),\n",
    "           ('Ball', 'Strike'),\n",
    "           loc='upper right',\n",
    "           ncol=2,\n",
    "           fontsize=10)\n",
    "    ax.set_ylim(0, 6)\n",
    "    ax.set_xlim(-2, 2)\n",
    "    plt.show()\n",
    "\n",
    "# Your code goes here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might notice, that this data distribution makes it unfeasible to use linear decision boundaries. We will instead employ the kernel trick to transform our feature space in order to find a maximum-margin hyperplane between the labels. Here is another visualisation of the procedure:\n",
    "\n",
    "![Kernel Trick](https://www.researchgate.net/profile/Marouane-Hachimi/publication/340610860/figure/fig4/AS:880021191286786@1586824810950/Non-linear-classifier-using-Kernel-trick-16.ppm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a clean and handy dataframe with all the data, that we're interested in. Let's get ready to feed it into our SVM.\n",
    "\n",
    "Assign the part of the dataframes, which we will use to predict the label, to a new variable called `features`. Also assign the column with the labels to a new variable called `labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features: pd.DataFrame = None # Your code goes here\n",
    "labels: pd.Series = None # Your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test cell\n",
    "\n",
    "assert features is not None, \"Your features are not defined. Create a new dataframe called features by selecting the 'plate_x' and 'plate_z' columns from judge_df_cleaned\"\n",
    "assert labels is not None, \"Your labels are not defined. Create a new series called labels by selecting the 'label' column from judge_df_cleaned\"\n",
    "\n",
    "assert features.columns.to_list() == [\"plate_x\", \"plate_z\"], \"The plate x and z data should be in the features\"\n",
    "assert labels.name == \"label\", \"The label column could be the labels variable\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to test the quality of your model independently later on, so we will split our data in a training-set and a test-set again. Use the appropiate function a split your data. The test-set should contain 20% of the total data. Make sure, that the data was split correctly by having a look at the shape of the resulting matrices/arrays.\n",
    "\n",
    "Assign features and labels of your subsets to the variables `X_train, X_test, y_train, y_test`. To pass the test cell the sample size and amount of features has to be correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train: np.ndarray\n",
    "X_test: np.ndarray\n",
    "y_train: np.ndarray\n",
    "y_test: np.ndarray\n",
    "\n",
    "X_train, X_test, y_train, y_test = None, None, None, None # Your code goes here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test cell\n",
    "\n",
    "test_size: float = 0.2\n",
    "train_size: float = 1 - test_size\n",
    "\n",
    "assert X_train is not None, \"Your X_train is not defined. Use the train_test_split function to split the features into training and testing sets\"\n",
    "assert X_test is not None, \"Your X_test is not defined. Use the train_test_split function to split the features into training and testing sets\"\n",
    "assert y_train is not None, \"Your y_train is not defined. Use the train_test_split function to split the labels into training and testing sets\"\n",
    "assert y_test is not None, \"Your y_test is not defined. Use the train_test_split function to split the labels into training and testing sets\"\n",
    "\n",
    "assert len(X_train.shape) == 2, \"Your training set is not a 2D-Matrix\"\n",
    "assert len(X_test.shape) == 2, \"Your test set is not a 2D-Matrix\"\n",
    "if (len(X_train.shape) == 2) and (len(X_test.shape) == 2):\n",
    "    assert X_train.shape[1] == 2, \"Your training set should have 2 columns\"\n",
    "    assert X_test.shape[1] == 2, \"Your test set should have 2 columns\"\n",
    "    assert y_train.shape == (int(labels.shape[0] * train_size),), f\"y_train shape is {y_train.shape} instead of {(int(labels.shape[0] * train_size),)}. Your training set should contain {train_size*100}% of the data\"\n",
    "    assert y_test.shape == ((int(labels.shape[0] * test_size))+1,), f\"y_test shape is {y_test.shape} instead of {((int(labels.shape[0] * test_size))+1,)} . Your test set should contain {test_size*100}% of the data\"\n",
    "    assert X_train.shape == (int(features.shape[0] * train_size), features.shape[1]), f\"X_train shape is {X_train.shape} instead of {(int(features.shape[0] * train_size), features.shape[1])}\"\n",
    "    assert X_test.shape == ((int(features.shape[0] * test_size)+1), features.shape[1]), f\"X_test shape is {X_test.shape} instead of {((int(features.shape[0] * test_size)+1), features.shape[1])}\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training\n",
    "\n",
    "Now it's finally time to create our model, train it with our data, predict our test set and evaluate the models accuracy. Use an `rbf-kernel`, `C = 2`, and `gamma = 2` for now.\n",
    "\n",
    "Save the model to a variable called `model`, use the appropiate hyper parameters and fit the model to pass the test cell. Assign the prediction of the test set to a variable called `predictions_test` and it's accuracy to `accuracy_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model: SVC = None # Your code goes here\n",
    "\n",
    "predictions_test: np.ndarray = None # Your code goes here\n",
    "\n",
    "accuracy_test: float = None # Your code goes here\n",
    "print(f\"Accuracy: {accuracy_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test cell\n",
    "\n",
    "assert model is not None, \"model is not defined.\"\n",
    "assert model.kernel == \"rbf\", 'The model kernel should be \"rbf\"'\n",
    "assert model.C == 2, \"The C hyper parameter should be 2\"\n",
    "assert model.gamma == 2, \"The gamma hyper parameter should be 2\"\n",
    "assert hasattr(model, \"fit_status_\"), \"The model is not fitted\"\n",
    "\n",
    "assert predictions_test is not None\n",
    "assert accuracy_test > 0.7"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also print the confusion-matrix of your predictions as an assessment of the model-performance. Don't forget that labels you want to display are is the list [\"Balls\", \"Strikes\"]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final reward you get to plot the decision boundary. Call the ```plot_strike_zone```-function with your cleaned dataframe and your trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_strike_zone(df: pd.DataFrame, model: SVC) -> None:\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.scatter(df.plate_x, df.plate_z, c=df.label, cmap=plt.cm.coolwarm, alpha=0.2)\n",
    "    plt.title(\"Aaron Judge strike zone\")\n",
    "    ax.set_ylim(0, 6)\n",
    "    ax.set_xlim(-2, 2)\n",
    "    x_min, x_max = ax.get_xlim()\n",
    "    y_min, y_max = ax.get_ylim()\n",
    "    h = 0.04\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                        np.arange(y_min, y_max, h))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    ax.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.5)\n",
    "    plt.show()\n",
    "\n",
    "# Your code goes here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations on building your own SVM model!**\n",
    "\n",
    "If you are interested in the effects of the hyperparameters: Change the hyperparameters in your model construction, retrain it and plot the decision boundary again.\n",
    "\n",
    "If your thirst for baseball data is still not quenched(understandably), feel free to compare Judge's strike zone to that of a smaller player like Jose Altuve."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "interpreter": {
   "hash": "09479eb26e9c2dfedc5b750a5f4404419e7e88fc081728cd256fd3e13a96b5b1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
