{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Exercise\n",
    "\n",
    "In this exercise we'll work on our own implementation of linear regression models, compare it to existing regeression models and apply them to a chemical dataset predicting solubility of different molecules. First I'll import the relevant packages for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll also go ahead and prepare a suitable example dataset for your. It's a medical dataset of diabetes patients with medical information as features and some numerical quantification of the diabetes disease of that patient:\n",
    "\n",
    "**Number of Samples**: 442\n",
    "\n",
    "**Features**: 10 columns with numeric predictive values\n",
    "\n",
    "**Target**: Quantitative measure of disease progression one year after baseline\n",
    "\n",
    "**Feature Information**:\n",
    "- age: age in years\n",
    "- sex: 0 male, 1 female probably\n",
    "- bmi: body mass index\n",
    "- bp: average blood pressure\n",
    "- s1: tc, total serum cholesterol\n",
    "- s2: ldl, low-density lipoproteins\n",
    "- s3: hdl, high-density lipoproteins\n",
    "- s4: tch, total cholesterol / HDL\n",
    "- s5: ltg, possibly log of serum triglycerides level\n",
    "- s6: glu, blood sugar level\n",
    "\n",
    "**Note**: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times the square root of the number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_dataset: sklearn.utils.Bunch = datasets.load_diabetes() # Scikit-learn dataset, bunch object, similar to a dictionary\n",
    "diabetes_feature_names: list = diabetes_dataset.feature_names\n",
    "diabetes_features: np.ndarray = diabetes_dataset.data # you'll work with these features\n",
    "diabetes_targets: np.ndarray = diabetes_dataset.target # you'll predict this target\n",
    "diabetes_dataframe: pd.DataFrame = pd.DataFrame(data=diabetes_features, columns=diabetes_feature_names) # Just for convenience if you wanto explore the data\n",
    "diabetes_dataframe[\"target\"] = diabetes_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our ambitious goal for today is to not only cover simple linear regression, but multiple linear regression.\n",
    "\n",
    "A general formula for the multiple regression for `n` variables would look like this:\n",
    "\n",
    "$$\n",
    "  f_w(x_0,x_1,...,x_n) = w_{b} 1 + w_{0} x_0 + w_{1} x_1  + ... w_{n} x_n = \\sum_i^n w_i \\cdot x_i = \\mathbf{x} \\cdot \\mathbf{w} \n",
    "$$\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{x} =\n",
    "\\begin{pmatrix}\n",
    "  1 \\\\ x_0 \\\\ x_1 \\\\ \\cdots \\\\ x_n \\\\\n",
    "\\end{pmatrix},\n",
    "\\mathbf{w} = \n",
    "\\begin{pmatrix}\n",
    "  w_b \\\\ w_0 \\\\ w_1 \\\\ \\vdots \\\\ w_n  \\\\\n",
    "\\end{pmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "Following the least squares estimation we want to minimize the squared loss for the whole dataset with n features and T entries:\n",
    "\n",
    "\\begin{equation}\n",
    "L = ||\\mathbf{X} \\mathbf{w} - \\mathbf{y}||^2 = (\\mathbf{X} \\mathbf{w} - \\mathbf{y})^T(\\mathbf{X} \\mathbf{w} - \\mathbf{y}) = \\mathbf{X}^T \\mathbf{w}^T \\mathbf{X} \\mathbf{w} - \\mathbf{y}^T \\mathbf{X} \\mathbf{w} - \\mathbf{X}^T \\mathbf{w}^T \\mathbf{y} + y^T y = \\mathbf{X}^T \\mathbf{w}^T \\mathbf{X} \\mathbf{w} - 2 \\mathbf{X}^T \\mathbf{w}^T \\mathbf{y} + \\mathbf{y}^T \\mathbf{y}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{X} =\n",
    "\\begin{pmatrix}\n",
    "  1       & x_{0,0}   & x_{0,1}  & \\cdots  & x_{0,n}  \\\\\n",
    "  1       & x_{1,0}   & x_{1,1}  & \\cdots  & x_{1,n}  \\\\\n",
    "  \\vdots  & \\vdots  & \\vdots & \\ddots  & \\vdots \\\\\n",
    "  1       & x_{T,0 }  & x_{T,1}  & \\cdots  & x_{T,n}  \\\\\n",
    "\\end{pmatrix},\n",
    "\\mathbf{y} = \n",
    "\\begin{pmatrix}\n",
    "  1 & y_0 & y_1 & \\cdots & y_T  \\\\\n",
    "\\end{pmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "This is extreme when the derivation with respect to the weights is minimal:\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial L}{\\partial \\mathbf{w}} \\overset{!}{=} 0\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial L}{\\partial \\mathbf{w}} = -2 \\mathbf{X} \\mathbf{y} + 2 \\mathbf{X} \\mathbf{}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "With multivariate polynomial linear regression we \n",
    "\n",
    "First you'll have to create a 3D matrix, where each of the values in the 2D matrix features is calculated to the power of 0,1,2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1.00e+00  3.81e-02  1.45e-03]\n",
      "  [ 1.00e+00  5.07e-02  2.57e-03]\n",
      "  [ 1.00e+00  6.17e-02  3.81e-03]]\n",
      "\n",
      " [[ 1.00e+00 -1.88e-03  3.54e-06]\n",
      "  [ 1.00e+00 -4.46e-02  1.99e-03]\n",
      "  [ 1.00e+00 -5.15e-02  2.65e-03]]\n",
      "\n",
      " [[ 1.00e+00  8.53e-02  7.28e-03]\n",
      "  [ 1.00e+00  5.07e-02  2.57e-03]\n",
      "  [ 1.00e+00  4.45e-02  1.98e-03]]]\n"
     ]
    }
   ],
   "source": [
    "A = diabetes_features[:, :, np.newaxis] ** np.arange(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.04  0.05  0.06  0.02 -0.04 -0.03 -0.04 -0.    0.02 -0.02]\n",
      " [-0.   -0.04 -0.05 -0.03 -0.01 -0.02  0.07 -0.04 -0.07 -0.09]\n",
      " [ 0.09  0.05  0.04 -0.01 -0.05 -0.03 -0.03 -0.    0.   -0.03]\n",
      " [-0.09 -0.04 -0.01 -0.04  0.01  0.02 -0.04  0.03  0.02 -0.01]\n",
      " [ 0.01 -0.04 -0.04  0.02  0.    0.02  0.01 -0.   -0.03 -0.05]]\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
