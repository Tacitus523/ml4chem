{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b50a5450",
   "metadata": {},
   "source": [
    "# Exercise - Prediction of medicial conditions\n",
    "\n",
    "In today's exercise we will deal with an illness you might have heard of: Covid19. We will try to diagnose the condition the patient is in by classifying X-ray-images by either pneumonia, Covid-19 or no illness. There is an archive called **Covid19-dataset.zip**, which should be **unpacked in the same folder as this exercise** for the import to work without problems. The unpacked folder should be called **Covid19-dataset** and contain a **train** and a **test** subfolder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf0688a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-12 18:07:23.012130: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef5ffb3",
   "metadata": {},
   "source": [
    "### Covid19 X-ray image dataset\n",
    "\n",
    "First we will handle the import of the data. As we haven't dealed with this so far, I will provide you with a solution for this problem using the Tensorflow ImageDataGenerator, which will provide a constant stream of images as we need them. Some of the data handling might be different for this generator, but this will be pointed out. This also provides us with some handy tools to generate data from data, as we can manipulate the training-images by zooming, rotating and moving it up and down, which will make the model more transferable and work against overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecdce72b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/srv/nfs/home/dhoffmann/git/ml4chem/4_NeuralNet/Covid19-dataset/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m training_data_generator \u001b[38;5;241m=\u001b[39m ImageDataGenerator(\n\u001b[1;32m      6\u001b[0m     rescale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m256\u001b[39m, \n\u001b[1;32m      7\u001b[0m     zoom_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     height_shift_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m test_data_generator \u001b[38;5;241m=\u001b[39m ImageDataGenerator(\n\u001b[1;32m     13\u001b[0m     rescale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m256\u001b[39m\n\u001b[1;32m     14\u001b[0m )\n\u001b[0;32m---> 16\u001b[0m training_iterator \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_data_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow_from_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mTRAIN_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcategorical\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrayscale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m test_iterator \u001b[38;5;241m=\u001b[39m test_data_generator\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[1;32m     24\u001b[0m     TEST_PATH, \n\u001b[1;32m     25\u001b[0m     class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE,\n\u001b[1;32m     29\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4chem/lib/python3.9/site-packages/tensorflow/python/keras/preprocessing/image.py:942\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflow_from_directory\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    868\u001b[0m                         directory,\n\u001b[1;32m    869\u001b[0m                         target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    880\u001b[0m                         subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    881\u001b[0m                         interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;124;03m\"\"\"Takes the path to a directory & generates batches of augmented data.\u001b[39;00m\n\u001b[1;32m    883\u001b[0m \n\u001b[1;32m    884\u001b[0m \u001b[38;5;124;03m  Arguments:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;124;03m          and `y` is a numpy array of corresponding labels.\u001b[39;00m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 942\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDirectoryIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m      \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m      \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m      \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m      \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m      \u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_to_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m      \u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m      \u001b[49m\u001b[43msave_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m      \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m      \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4chem/lib/python3.9/site-packages/tensorflow/python/keras/preprocessing/image.py:380\u001b[0m, in \u001b[0;36mDirectoryIterator.__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    378\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mfloatx()\n\u001b[1;32m    379\u001b[0m   kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m dtype\n\u001b[0;32m--> 380\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mDirectoryIterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_data_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_to_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml4chem/lib/python3.9/site-packages/keras_preprocessing/image/directory_iterator.py:115\u001b[0m, in \u001b[0;36mDirectoryIterator.__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[1;32m    114\u001b[0m     classes \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m    116\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, subdir)):\n\u001b[1;32m    117\u001b[0m             classes\u001b[38;5;241m.\u001b[39mappend(subdir)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/srv/nfs/home/dhoffmann/git/ml4chem/4_NeuralNet/Covid19-dataset/train'"
     ]
    }
   ],
   "source": [
    "TRAIN_PATH = os.path.abspath(\"Covid19-dataset/train\")\n",
    "TEST_PATH = os.path.abspath(\"Covid19-dataset/test\")\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "training_data_generator = ImageDataGenerator(\n",
    "    rescale=1.0/256, \n",
    "    zoom_range=0.2, \n",
    "    rotation_range=15, \n",
    "    width_shift_range=0.05, \n",
    "    height_shift_range=0.05\n",
    ")\n",
    "test_data_generator = ImageDataGenerator(\n",
    "    rescale=1.0/256\n",
    ")\n",
    "\n",
    "training_iterator = training_data_generator.flow_from_directory(\n",
    "    TRAIN_PATH, \n",
    "    class_mode=\"categorical\",\n",
    "    color_mode=\"grayscale\", \n",
    "    target_size=(256,256), \n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False)\n",
    "test_iterator = test_data_generator.flow_from_directory(\n",
    "    TEST_PATH, \n",
    "    class_mode=\"categorical\", \n",
    "    color_mode=\"grayscale\", \n",
    "    target_size=(256,256),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1456cb2",
   "metadata": {},
   "source": [
    "Here are some example pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765e75b9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3)\n",
    "plt.subplots_adjust(top=1.5,wspace=0.3)\n",
    "\n",
    "for i, condition_num in enumerate([(\"Normal\", 1), (\"Pneumonia\", 0), (\"Covid\", 2)]):\n",
    "    condition, num = condition_num\n",
    "    ax = axs[i]\n",
    "    img_path = os.path.abspath(f\"Covid19-dataset/train/{condition}/{num}.png\")\n",
    "    img = mpimg.imread(img_path)\n",
    "    ax.imshow(img, cmap=plt.get_cmap('gray'))\n",
    "    ax.set_title(f\"{condition}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf98089a",
   "metadata": {},
   "source": [
    "### Creating the model\n",
    "\n",
    "The images are scaled to a size of 256x256 pixels and will have one color-channel(greyscale). Our first layer of our Sequential model will therefore be an InputLayer with an input_shape of (256,256,1). Our next layers for convolutional operations are supposed to be:\n",
    "- a Conv2D-layer with 3 filters, a 3x3 filter-size, a stride of 1 and a relu-activation-function\n",
    "- a MaxPooling2D-layer with a pool-size and a stride of 3x3\n",
    "- a Conv2D-layer with 3 filters, a 3x3 filter-size, a stride of 1 and a relu-activation-function\n",
    "- a MaxPooling2D-layer with a pool-size and a stride of 3x3\n",
    "- a Flatten-layer to switch to a regular fully-connected network\n",
    "\n",
    "The fully-connected part should have:\n",
    "- a Dense-layer with 50 neurons and a relu-activation\n",
    "- a Dense-layer with 20 neurons and a relu-activation\n",
    "- a Dense-layer with an appropiate amount of neurons and a suitable activation-function for our 3 class classification-problem\n",
    "\n",
    "Print a summary of the model.\n",
    "\n",
    "\n",
    "Create a Sequential model called `model` with the specified layers to pass the test cell. Only the specifications of the last layer are checked, as this is the most important one and responsible for results, that make sense.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8afc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd53de8a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert isinstance(model, keras.src.engine.sequential.Sequential), \"The variable model should be assigned to a Sequential model\"\n",
    "assert len(model.layers) == 8, \"The model should have 8 layers without the InputLayer\"\n",
    "\n",
    "target_layers = [\n",
    "    (keras.src.layers.convolutional.conv2d.Conv2D, \"Conv2D\"),\n",
    "    (keras.src.layers.pooling.max_pooling2d.MaxPooling2D, \"MaxPooling2D\"),\n",
    "    (keras.src.layers.convolutional.conv2d.Conv2D, \"Conv2D\"),\n",
    "    (keras.src.layers.pooling.max_pooling2d.MaxPooling2D, \"MaxPooling2D\"),\n",
    "    (keras.src.layers.reshaping.flatten.Flatten, \"Flatten\"),\n",
    "    (keras.src.layers.core.dense.Dense, \"Dense\"),\n",
    "    (keras.src.layers.core.dense.Dense, \"Dense\"),\n",
    "    (keras.src.layers.core.dense.Dense, \"Dense\"),\n",
    "]\n",
    "\n",
    "for i in range(len(model.layers)):\n",
    "    assert isinstance(model.layers[i], target_layers[i][0]), f\"The {i}th layer should be a {target_layers[i][0]} layer\"\n",
    "\n",
    "assert model.layers[-1].get_config()[\"units\"] == 3, \"The final number of neurons should be 3, as we have 3 classes (Normal, Pneumonia, Covid).\"\n",
    "assert model.layers[-1].get_config()[\"activation\"] == \"softmax\", \"The final activation function should be the softmax function.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89069ab2",
   "metadata": {},
   "source": [
    "Compile the model with the Adam-optimizer with a learning_rate of 0.0005, CategoricalCrossentropy-loss and keep track of the accuracy metric to pass the test cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df58001c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e121a1a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert model.optimizer is not None and model.loss is not None, \"The model is not compiled yet\"\n",
    "assert isinstance(model.loss, keras.src.losses.CategoricalCrossentropy) or model.loss==\"categorical_crossentropy\", \"The Loss should be the categorical cross entropy loss\"\n",
    "assert isinstance(model.optimizer, keras.src.optimizers.adam.Adam), \"The optimizer should be the Adam optimizer\"\n",
    "assert np.isclose(0.0005, model.optimizer.learning_rate.numpy()), \"The Adam optimizer should have a learning rate of 0.0005\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec55f35",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "\n",
    "Start the training! It should last for 40 epochs. As you supply the training_iterator as training data, you don't have to specify the output-data. Also the batch_size is determined by the iterator and shuffling the data is not possible. We won't give any validation data. If you want, turn the verbosity to 0 to supress the information about the proceeding of the training or 2 to return minimal information each epoch.\n",
    "\n",
    "Make sure to save the history-object to a variable called history and to use 40 epochs to pass the test cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab80cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d847e6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "assert len(history.history[\"loss\"]) == 40, \"You should use 40 epochs for now\"\n",
    "assert history.history[\"accuracy\"][-1] > 0.75, \"The training does not appear to be particularly successful as the accuracy is low\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6763d3ee",
   "metadata": {},
   "source": [
    "### Evaluating the model\n",
    "\n",
    "Plot the loss and the accuarcy during the training. How is the convergence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3fed94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7c8bd27",
   "metadata": {},
   "source": [
    "Figure out the loss and the accuracy for the test-set with your trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68340fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f6dbcd3",
   "metadata": {},
   "source": [
    "Finally plot the confusion-matrix for the predictions.\n",
    "\n",
    "Hint 1: You can get the true classes of your test_iterator by accessing test_iterator.classes\n",
    "\n",
    "Hint 2: Which number belongs to which class is saved in test_iterator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9697ad74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b06dd8c3",
   "metadata": {},
   "source": [
    "That's it from our side. We hope you could get some insight into Machine Learing methods and could pick up some Python!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
