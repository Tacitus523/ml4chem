{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your own logistic regression model\n",
    "\n",
    "This time it's your turn to create a logistic regression model. The [dataset](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)), that we're going to work with, contains diagnostic information about breast cancer. The medical features of individual tumors like size, shape and smoothness were measured. The tumors are labeled as **malignant**(0) or **benign**(1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer(as_frame=True)\n",
    "features = data[\"data\"]\n",
    "feature_names = data[\"feature_names\"]\n",
    "labels = data[\"target\"]\n",
    "label_names = data[\"target_names\"]\n",
    "\n",
    "print(features.columns)\n",
    "print(labels[15:20])\n",
    "print(label_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration\n",
    "\n",
    "Let's have a closer look on the distribution of the data. How many tumors are there in the dataset overall? Also find out how many tumors were classified as malignant and how many as benign. Is this a well balanced dataset or is one kind overrepresented?\n",
    "\n",
    "Assign the amount of malignant tumors to a variable called `n_malignant` and the amount of benign tumors to a variable `n_benign` to pass the tests in the following test cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n_malignant = None\n",
    "n_benign = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test cell\n",
    "\n",
    "assert n_malignant == 53*4, f\"n_malignant should be {53*4}\"\n",
    "assert n_benign == 119*3, f\"n_benign should be {119*3}\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we should deal with the features and decide if we have to preprocess them or use them as they are. What are the datatypes of the features? If they are non-numerical we need to convert them to quantify them. Are there any missing values or NaNs(not-a-number)?\n",
    "\n",
    "Assign the variables `need_to_convert_non_numerical` and `need_to_convert_nan` to `True` or `False` depending on the need to deal with this data type within this dataset to pass the test cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "need_to_convert_non_numerical = None\n",
    "need_to_convert_nan = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test cell\n",
    "\n",
    "assert (not need_to_convert_non_numerical) and (need_to_convert_non_numerical is not None), \"Which column contains non_numerical values? How do you know?\"\n",
    "assert (not need_to_convert_nan) and (need_to_convert_nan is not None), \"Which column contains NAN values? How do you know?\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at a specific column. What is the mean and the standard deviation of the \"mean radius\" of the tumors?\n",
    "Can you test if there is a correlation between \"mean radius\", \"mean perimeter\" and \"mean area\"?\n",
    "\n",
    "Hint: You can access a sub-dataframe of a pandas-dataframe by giving it a list of columns as its index:\n",
    "\n",
    "```my_subframe = my_dataframe[[\"column1\",\"column2\",\"column3\"]]```\n",
    "\n",
    "Assign the mean and the standard_deviation of the \"mean radius\" column to variables called `mean_radius_mean` and `mean_radius_std` to pass the test cell. Also assign a `variable geometry_properties_correlated` to `True` or `False` depending on if you found a the mean radius\", \"mean perimeter\" and \"mean area\" column to be strongly correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_radius_mean = None\n",
    "mean_radius_std = None\n",
    "\n",
    "\n",
    "geometry_properties_correlated = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test cell\n",
    "\n",
    "assert np.isclose(mean_radius_mean*mean_radius_std, 49.785265873530975, rtol=1e-03, atol=1e-04), \"One or both of the mean and the std of mean_radius seem to be off. Did you pick the right column?\"\n",
    "\n",
    "assert geometry_properties_correlated, \"Why wouldn't radius, diameter and area be correlated?\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "To validate your model in the end you will need a separate test set. Therefore you should split your data in two random subsets for training and testing now. Your test set should contain 15% of your total dataset. Also make sure, that both your subsets have the expected sample size.\n",
    "\n",
    "Assign features and labels of your subsets to the variables `X_train, X_test, y_train, y_test`. To pass the test cell the sample size and amount of features has to be correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test cell\n",
    "\n",
    "assert y_train.shape == (483,), \"Your training set does not contain 85% of the data\"\n",
    "assert y_test.shape == (86,), \"Your test set does not contain 15% of the data\"\n",
    "\n",
    "assert X_train.shape[0] == 483, \"Your training set does not contain 85% of the data\"\n",
    "assert X_test.shape[0] == 86, \"Your test set does not contain 15% of the data\"\n",
    "assert len(X_train.shape) == 2, \"Your training set is not a 2D-Matrix\"\n",
    "assert len(X_test.shape) == 2, \"Your test set is not a 2D-Matrix\"\n",
    "if (len(X_train.shape) == 2) and (len(X_test.shape) == 2):\n",
    "    assert X_train.shape == (483, 30), \"Your training set does not contain all 30 features of the dataset\"\n",
    "    assert X_test.shape == (86, 30), \"Your test set does not contain all 30 features of the dataset\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize the training data and the test data with the mean and the standard deviation of the training data.\n",
    "\n",
    "Assign the scaled values to variables called `X_train_scaled` and `X_test_scaled`. To pass the test cell the mean and standard deviation of `X_train_scaled` should be very close 0 and 1, while mean and standard deviation of `X_test_scaled` has to have a little deviation from 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train_scaled = None\n",
    "X_test_scaled = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test cell\n",
    "\n",
    "assert np.allclose(X_train_scaled.mean(axis=0), np.zeros(shape=(30,))), \"The mean of all columns of X_train_scaled is not close to 0\"\n",
    "assert np.allclose(X_train_scaled.std(axis=0), np.ones(shape=(30,))), \"The standard deviation of all columns of X_train_scaled is not close to 0\"\n",
    "\n",
    "assert not np.allclose(X_test_scaled.mean(axis=0), np.zeros(shape=(30,))), \"The mean of all columns of X_test_scaled is suspiciously close to 0\"\n",
    "assert not np.allclose(X_test_scaled.std(axis=0), np.ones(shape=(30,))), \"The standard deviation of all columns of X_test_scaled is suspiciously close to 0\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "Now it's finally time to create your LogisticRegression model and fit it to the data in your training-set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate your model by a metric of your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally visualize the results of your prediction in a confusion-matrix. Don't forget, that labels you want to display, are is the list [\"malignant\", \"benign\"]. This list still saved in the variable `label_names`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now we classify the tumors straight up according to which one has the higher probability, the decision-treshold is 0.5, which makes sense in most cases. In other cases we can improve the model by adjusting the decision-threshold, e.g. a tumor has to have a probability of 90% to be classified as benign otherwise we will classify it as malignant. This might even make sense, if it lowers the accuracy of the model, especially in this example. Why?\n",
    "\n",
    "The next code cell offers a way to play around with different decision thresholds. Call the `test_different_thresholds` function with your variable and a threshold list of your choice(```my_function(my_argument1, my_argument2,...)```) to have a look at how the threshold affects the prediction outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_list = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "\n",
    "def test_different_thresholds(model, X_test_scaled, y_test, threshold_list):\n",
    "    pred_proba = model.predict_proba(X_test_scaled)\n",
    "    \n",
    "    for threshold in threshold_list:\n",
    "        print (f\"\\n******** For threshold ={threshold: .1f} ******\")\n",
    "        Y_test_pred = (pred_proba[:,1] > threshold).astype(int)\n",
    "        test_accuracy = metrics.accuracy_score(y_test, Y_test_pred)\n",
    "        print(f\"Our testing accuracy is {test_accuracy: .2f}\")\n",
    "\n",
    "        print(confusion_matrix(y_test, Y_test_pred))\n",
    "        \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations on building your own logistic regression model!**"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "interpreter": {
   "hash": "09479eb26e9c2dfedc5b750a5f4404419e7e88fc081728cd256fd3e13a96b5b1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
