{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Exercise\n",
    "\n",
    "In this exercise you'll build your own decision tree to predict wine quality based on its ingredients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, accuracy_score, precision_score, recall_score, f1_score, mean_absolute_error, r2_score\n",
    "\n",
    "np.set_printoptions(precision=2) # numpy prints all numbers up to 2nd decimals "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data data is taken from [*P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. In Decision Support Systems, Elsevier*](https://archive.ics.uci.edu/dataset/186/wine+quality). The inputs include objective tests (e.g. PH values) and the output is based on sensory data(median of at least 3 evaluations made by wine experts). Each expert graded the wine quality between 0 (very bad) and 10 (very excellent) of red and white variants of the Portuguese \"Vinho Verde\" wine.\n",
    "\n",
    "\n",
    "Input variables (based on physicochemical tests):\n",
    "\n",
    "1. fixed acidity\n",
    "2. volatile acidity\n",
    "3. citric acid\n",
    "4. residual sugar\n",
    "5. chlorides\n",
    "6. free sulfur dioxide\n",
    "7. total sulfur dioxide\n",
    "8. density\n",
    "9. pH\n",
    "10. sulphates\n",
    "11. alcohol\n",
    "12. color\n",
    "\n",
    "Output variable (based on sensory data): \n",
    "\n",
    "13. quality (score between 0 and 10)\n",
    "\n",
    "I'll import the data for you. Note, that the dataset mostly contains wines of mediocre quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wines: pd.DataFrame = pd.read_csv('winequality.csv')\n",
    "print(wines[\"quality\"].value_counts().sort_index())\n",
    "wines.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might notice that the `color` column is an odd one out. It's a categorical column in a otherwise numerical dataset. The Decision Tree will have difficulty to deal with this, so start by converting the categorical data as string to a numerical datatype.\n",
    "\n",
    "Another less obvious problem is, that the data type of quality is an integer. It's not a direct problem, but the plotting function expects string classes. Transform it to strings as well now.\n",
    "\n",
    "Transform the `color` column to a categorical datatype and create the new column `color numerical` by using its category codes. Alternatively, map the values of `color` to `1` for `\"white\"` and `0` for `\"red\"` to create the new `color numerical` column. Also transform the `quality` column to the `str` datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wines[\"color\"] = None # Your code here, optionally\n",
    "wines[\"color numerical\"] = None # Your code here\n",
    "wines[\"quality\"] = None # Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Test cell\n",
    "\n",
    "assert \"color numerical\" in wines.columns, \"The column 'color numerical' is missing. Create it by converting the 'color' column to a numerical value.\"\n",
    "assert wines[\"color numerical\"].nunique() == 2, \"The 'color numerical' column should have 2 unique values.\"\n",
    "assert np.array(wines[\"color numerical\"].unique() == [1, 0]).all(), \"The 'color numerical' column should have the values 0 and 1.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create a sub-`pd.DataFrame` of the features and a `pd.Series` with the target for the wine quality prediction. Also, split the features and the target into a train and a test set. The test set should contain 20% of the data.\n",
    "\n",
    "Create a `pd.DataFrame` called `features` and a `pd.Series` called `target`. Split these two variables into the variables `X_train`, `X_test`, `y_train`, `y_test` with the test variables containing 20% of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features: pd.DataFrame = None # Your code here\n",
    "target: pd.Series = None # Your code here\n",
    "\n",
    "X_train: np.ndarray\n",
    "X_test: np.ndarray\n",
    "y_train: np.ndarray\n",
    "y_test: np.ndarray\n",
    "X_train, X_test, y_train, y_test = None # Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Test cell\n",
    "\n",
    "test_size: float = 0.2\n",
    "train_size: float = 1 - test_size\n",
    "\n",
    "assert features is not None, \"The 'features' DataFrame is missing.\"\n",
    "assert target is not None, \"The 'target' Series is missing.\"\n",
    "assert X_train is not None, \"The 'X_train' array is missing.\"\n",
    "assert X_test is not None, \"The 'X_test' array is missing.\"\n",
    "assert y_train is not None, \"The 'y_train' array is missing.\"\n",
    "assert y_test is not None, \"The 'y_test' array is missing.\"\n",
    "\n",
    "assert features.shape[1] == 12, f\"The 'features' DataFrame has the wrong number of columns. Expected: 12, Actual: {features.shape[1]}\"\n",
    "\n",
    "assert X_train.shape[0] == int(wines.shape[0] * train_size), f\"The training set has the wrong number of samples. Expected: {int(wines.shape[0] * train_size)}, Actual: {X_train.shape[0]}\"\n",
    "assert X_test.shape[0] == int(wines.shape[0] * test_size)+1, f\"The test set has the wrong number of samples. Expected: {int(wines.shape[0] * test_size)+1}, Actual: {X_test.shape[0]}\"\n",
    "assert y_train.shape[0] == int(wines.shape[0] * train_size), f\"The training set has the wrong number of labels. Expected: {int(wines.shape[0] * train_size)}, Actual: {y_train.shape[0]}\"\n",
    "assert y_test.shape[0] == int(wines.shape[0] * test_size)+1, f\"The test set has the wrong number of labels. Expected: {int(wines.shape[0] * test_size)+1}, Actual: {y_test.shape[0]}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your decision Tree. We now have a much higher dimensional problem and even worse: more possible classes. Our tree will be therefore much larger until a proper classification is possible. Let's use a depth of 12 levels.\n",
    "\n",
    "Create a variable for your tree called `tree_model`. Use a depth of 12, the gini-criterion and show it a random subset of 80% of the features at each level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model: tree.DecisionTreeClassifier = None # Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Test cell\n",
    "\n",
    "assert tree_model is not None, \"The model is missing. You should create a decision tree model.\"\n",
    "assert tree_model.max_depth == 12, \"The model should have a max depth of 12.\"\n",
    "assert tree_model.criterion == \"gini\", \"The model should use the 'gini' criterion.\"\n",
    "assert tree_model.max_features == 0.8, \"The model should use 80% of the features.\"\n",
    "assert hasattr(tree_model, \"tree_\"), \"The model has not been trained. You should fit the model to the training data.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can try to plot the tree, but with 12 levels you need a quite large figure. Feel free to comment out the code and get an impression of the tree. Ideally, the final leaf nodes should be pure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(400, 30))\n",
    "# tree.plot_tree(tree_model, feature_names=features_list, class_names=tree_model.classes_, filled=True, precision=1, fontsize=5)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have trained the model, we can use it to make predictions on the test set. We can then evaluate the model's performance by comparing the predicted labels to the actual labels in the test set.\n",
    "\n",
    "Then, calculate the accuracy and recall of the model using the test set labels and the predicted labels.\n",
    "Plot the confusion matrix using the test set labels and the predicted labels.\n",
    "Finally, convert the true and and predicted labels to numerical values again and also calculate the mean absolute error to assess how wrong the model is on average. Also the R2-score will give you a comparison to simply guessing the mean of the distribution.\n",
    "\n",
    "Create a variable called `y_predict` and assign it the predicted labels for the test set. Assign the `accuarcy`, `recall`, and `MAE` to variables of the same name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict: np.ndarray = None # Your code here\n",
    "\n",
    "accuracy: float = None # Your code here\n",
    "recall: float = None # Your code here\n",
    "MAE: float = None # Your code here\n",
    "R2: float = None # Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "source": [
    "Instead of using a single decision tree, you can use a random forest to improve the model's performance. A random forest is an ensemble learning method that creates multiple decision trees and combines their predictions. This approach can help reduce overfitting and improve the model's accuracy.\n",
    "\n",
    "Create a random forest classifier named `forest_model` with the following parameters: - n_estimators: 100 - max_depth: 12 - criterion: \"gini\" - max_features: 0.8.\n",
    "Fit the model to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_model: RandomForestClassifier = None # Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Test cell\n",
    "\n",
    "assert forest_model is not None, \"The model is missing. You should create a random forest model.\"\n",
    "assert forest_model.n_estimators == 500, \"The model should have 500 estimators.\"\n",
    "assert forest_model.max_depth == 12, \"The model should have a max depth of 12.\"\n",
    "assert forest_model.criterion == \"gini\", \"The model should use the 'gini' criterion.\"\n",
    "assert forest_model.max_features == 0.8, \"The model should use 80% of the features.\"\n",
    "assert hasattr(forest_model, \"estimators_\"), \"The model has not been trained. You should fit the model to the training data.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can evaluate the model using the test data and the metrics we have used before.\n",
    "\n",
    "Create a variable called `y_predict` and assign it the predicted labels for the test set. Assign the `accuarcy`, `recall`, `MAE`, and `R2` to the variables `accuracy`, `recall`, `MAE`, and `R2` respectively and print them. Finally, print the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict: np.ndarray = None # Your code here\n",
    "\n",
    "accuracy: float = None # Your code here\n",
    "recall: float = None # Your code here\n",
    "MAE: float = None # Your code here\n",
    "R2: float = None # Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did the forst perform better than the tree? Can you still improve the results?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4chem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
